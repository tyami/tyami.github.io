---
title: "부스팅 앙상블(Ensemble) 2: Gradient Boosting"
excerpt: "Boosting 알고리즘 중 하나인 Gradient Boosting을 정리해봅시다"

categories:
- Machine learning

tags:
- Machine learning
- Ensemble
- Algorithm
- Boosting

toc: true
toc_sticky: true
toc_label: "Gradient Boosting"

use_math: true
---

이전 글 보기: [부스팅 앙상블(Ensemble) 1: AdaBoost](https://tyami.github.io/machine%20learning/ensemble-3-boosting-AdaBoost)

> 이전 포스팅에서는 부스팅 앙상블의 초기 모델인 AdaBoost에 대해 설명했습니다.
> 이번 포스팅에서는 AdaBoost보다 조금 더 진보된 부스팅 앙상블 모델인 Gradient Boosting 알고리즘에 대해 정리해보겠습니다.

- 참고자료 (Youtube): [Gradient Boost Part 1: Regression Main Ideas](https://www.youtube.com/watch?v=3CC4N4z3GJc) by StatQuest 
 
## Gradient Boosting



---

### Gradient Boosting Basics

---

### Gradient Boosting 학습 순서


> 다음 포스팅에서는 GBM 모델의 단점을 개선해서 Kaggle 등 대회에서 많이 사용되는 XGBoost 모델에 대해 정리해보도록 하겠습니다.

다음 글 보기: [부스팅 앙상블(Ensemble) 3: XGBoost](https://tyami.github.io/machine%20learning/ensemble-5-boosting-XGBoost/)