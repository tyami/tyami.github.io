---
title: "부스팅 앙상블 (Boosting Ensemble) 3: XGBoost"
excerpt: "Boosting 알고리즘 중 하나인 XGBoost을 정리해봅시다"

categories:
- Machine learning

tags:
- Machine learning
- Ensemble
- Algorithm
- Boosting

toc: true
toc_sticky: true
toc_label: "XGBoost"

use_math: true
---

이전 글 보기: [부스팅 앙상블 (Boosting Ensemble) 2: Gradient Boosting](https://tyami.github.io/machine%20learning/ensemble-5-boosting-gradient-boosting/)

> 이전 포스팅에서는 부스팅 앙상블의 초기 모델인 Gradient Boosting에 대해 설명했습니다.
> 이번 포스팅에서는 최근 Kaggle에서 높은 점수를 기록하고 있는 XGBoost 알고리즘에 대해 정리해보겠습니다.
 
## XGBoost 
XGBoost는 2016년 Tianqi Chen과 Carlos Guestrin 가 [XGBoost: A Scalable Tree Boosting System](https://arxiv.org/abs/1603.02754) 라는 논문으로 발표한 이후 Kaggle에서 놀라운 성능을 보이며 알려졌습니다.

---

### XGBoost Basics

---

### XGBoost 학습 순서

---

### Python code
Python 에서는 `xgboost` library로 사용 가능합니다.

- [XGBoost Docs](https://xgboost.readthedocs.io/en/latest/)

```python

```

> 다음 포스팅에서는 빠른 속도와 준수한 성능을 자랑하는 Microsoft의 LightGBM 모델에 대해 정리해보겠습니다.

다음 글 보기: [부스팅 앙상블 (Boosting Ensemble) 3: XGBoost](https://tyami.github.io/machine%20learning/ensemble-6-boosting-XGBoost/)
